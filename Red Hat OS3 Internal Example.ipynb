{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: overpass;\">Step 1: Paste the key and token info in the following cell and run</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'insert here'\n",
    "CONSUMER_SECRET = 'insert here'\n",
    "ACCESS_TOKEN = 'insert here'\n",
    "ACCESS_TOKEN_SECRET = 'insert here' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: overpass;\">Step 2: Run the following cell and enter in the search words/phrases as prompted</h1>\n",
    "<h3 style=\"font-family: overpass;\">Note: See Twitter Advanced Search documentation for more info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Search String Entry\\n\")\n",
    "search_string_all = raw_input(\"All of these words: \")\n",
    "search_string_exact = raw_input(\"This exact phrase: \")\n",
    "search_string_any = raw_input(\"Any of these words: \")\n",
    "search_string_none = raw_input(\"None of these words: \")\n",
    "\n",
    "# This is used in case the following cell is accidentally run more than once!\n",
    "search_is_new = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: overpass;\">Step 3:  Run each of the following cells in sequence to get the results!</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if search_is_new: \n",
    "    if search_string_exact: \n",
    "        search_string_exact = '\\\"' + search_string_exact + '\\\"'\n",
    "    if search_string_any: \n",
    "        search_string_any = search_string_any.replace(\" \", \" OR \")\n",
    "    if search_string_none: \n",
    "        search_string_none = \"-\" + search_string_none.replace(\" \", \" -\")\n",
    "    \n",
    "    search_string_list = [search_string_all, search_string_exact, search_string_any, search_string_none]\n",
    "    search_string_list = filter(None, search_string_list)\n",
    "    search_string = \" \".join(search_string_list)\n",
    "    \n",
    "    # Now that we've done this bit, we don't want to accidentally overdo it if we run this cell twice or more!\n",
    "    search_is_new = False\n",
    "\n",
    "print(\"Your search string is: \\'\" + search_string + \"\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import tweepy\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyprind as pp\n",
    "\n",
    "\"\"\"ts = twitter.Twitter(auth=twitter.OAuth(ACCESS_TOKEN, \n",
    "                ACCESS_TOKEN_SECRET, CONSUMER_KEY, \n",
    "                CONSUMER_SECRET))\n",
    "\n",
    "def isAuth():\n",
    "    return bool(isinstance(ts, twitter.api.Twitter))\n",
    "\n",
    "print('Authentification successful: %s' %isAuth())\"\"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "tweets_txt = []\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q=search_string,\n",
    "                           count=100,\n",
    "                           result_type=\"recent\",\n",
    "                           include_entities=True,\n",
    "                           lang=\"en\").items():\n",
    "    tweets_txt.append(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The search resulted in %s tweets\"  %len(tweets_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used for pulling overpass font if necessary\n",
    "import urllib\n",
    "urllib.urlretrieve(\"https://github.com/RedHatBrand/Overpass/releases/download/3.0.2/overpass-desktop-fonts.zip\", \"overpass.zip\")\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('./overpass.zip', 'r')\n",
    "zip_ref.extractall('./overpass_font/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Gather all the tweets together\n",
    "words = ' '.join(tweets_txt)\n",
    "\n",
    "# Remove URLs, RTs, and Twitter handles\n",
    "no_urls_no_tags = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                      font_path='./overpass_font/overpass/overpass-regular.otf',\n",
    "                      stopwords=STOPWORDS,\n",
    "                      background_color='white',\n",
    "                      width=1800,\n",
    "                      height=1400\n",
    "                     ).generate(no_urls_no_tags)\n",
    "\n",
    "import random\n",
    "\n",
    "def rh_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    cols = [\"hsl(0, 100%, 40%)\", \"hsl(0, 100%, 32%)\", \"hsl(0, 100%, 25%)\", \"hsl(0, 0%, 0%)\"]\n",
    "    return random.choice(cols)\n",
    "\n",
    "wc = wordcloud.recolor(color_func=rh_color_func, random_state=3)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(wc)\n",
    "plt.axis('off')\n",
    "'''plt.savefig('my_twitter_wordcloud_1.png', dpi=300)'''\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for tweet in tweets_txt:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    print(\"{:-<65} {}\".format(tweet.encode(\"utf-8\"), str(vs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentscores = []\n",
    "for tweet in tweets_txt:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    sentscores.append(vs['compound'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print('Mean score: %5.3f' %np.mean(sentscores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
